{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37ba44d1",
   "metadata": {},
   "source": [
    "# 이민정 week5 문제 풀이"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad03f0e",
   "metadata": {},
   "source": [
    "torch import하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "9d95206c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8e0d27",
   "metadata": {},
   "source": [
    "Q1. 가장 먼저 학습 데이터를 준비해보도록 하겠습니다. MNIST 데이터셋을 직접 Load\n",
    "해 봅시다. 데이터셋을 로드하고 DataLoader를 구현해보세요.\n",
    "\n",
    "- DataLoader를 이용해 MNIST 데이터셋을 로드해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "1ac63ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_epochs = 15 #training 반복 횟수\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "4c5e97f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "root = './data'\n",
    "\n",
    "#transforms.ToTensor(): Convert a PIL(파이썬 이미지 분석 라이브러리) Image or numpy.ndarray to tensor\n",
    "\n",
    "mnist_train = dsets.MNIST(root=root, train=True, transform=transforms.ToTensor(), download=True)\n",
    "mnist_test = dsets.MNIST(root=root, train=False, transform=transforms.ToTensor(), download=True)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(mnist_train, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "test_loader = torch.utils.data.DataLoader(mnist_test, batch_size=batch_size, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9ccdd2",
   "metadata": {},
   "source": [
    "Q2.데이터가 준비가 되었다면, 이제 그 데이터를 학습할 모델을 구현할 차례입니다. 그 후 모델 안의 가중치를 초기화시켜보세요. 입력 데이터 형태에 맞도록 linear한 모델을 구성해보세요.\n",
    "\n",
    "- MNIST 입력의 크기는 28x28입니다.\n",
    "\n",
    "- 여기서 구현하는 linear 모델은 입력이 1차원이기 때문에 입력 차원을 맞춰보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "daf82669",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-1.0262, -1.0838, -0.0223,  ..., -1.6097,  0.2824, -0.0643],\n",
       "        [ 0.6493,  0.6819, -0.1329,  ..., -0.4401,  0.1927, -0.7319],\n",
       "        [ 0.3524, -1.6678,  0.0317,  ..., -0.7048,  0.2957,  0.8456],\n",
       "        ...,\n",
       "        [ 0.1587,  0.7049,  0.4860,  ...,  0.7190,  1.2466, -0.4460],\n",
       "        [ 0.1118, -0.0316,  0.4709,  ...,  2.0205, -0.6535,  1.6389],\n",
       "        [ 1.0071, -0.4865,  0.7262,  ..., -0.0762, -1.7246,  0.0552]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "linear = torch.nn.Linear(28*28, 10, bias=True).to(device)\n",
    "\n",
    "#weight init\n",
    "torch.nn.init.normal_(linear.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0007df9",
   "metadata": {},
   "source": [
    "Q3. 위에서 구현한 모델을 학습시키기 위해서는 loss 함수와 opitmizer가 필요합니다. 아래 제시된 loss 함수와 optimizer를 구현해보세요. Loss 함수와 optimizer는 모델 안의 가중치를 업데이트 할 때 사용됩니다.\n",
    "\n",
    "옵티마이저는 SGD, Loss는 Cross Entropy Loss를 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "dc66c5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss fn - Cross Entropy Loss\n",
    "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "#optimizer - SGD\n",
    "optimizer = torch.optim.SGD(linear.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0839808",
   "metadata": {},
   "source": [
    "Q4. 3번 문제까지 해결하셨다면, 이제 학습을 위한 준비는 거의 끝났다고 볼 수 있습니다. 위 구현 함수들을 이용해 학습 Loop를 구현해보세요.\n",
    "\n",
    "- 위에서 구현한 모델, optimzer, loss fn 등을 이용해 학습을 구현해주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "22eedc88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/15], Step [100/600], Loss: 3.6108, Accuracy: 43.00%\n",
      "Epoch [1/15], Step [200/600], Loss: 1.9255, Accuracy: 59.00%\n",
      "Epoch [1/15], Step [300/600], Loss: 1.9646, Accuracy: 68.00%\n",
      "Epoch [1/15], Step [400/600], Loss: 1.7222, Accuracy: 71.00%\n",
      "Epoch [1/15], Step [500/600], Loss: 1.3860, Accuracy: 75.00%\n",
      "Epoch [1/15], Step [600/600], Loss: 0.8740, Accuracy: 76.00%\n",
      "Epoch [2/15], Step [100/600], Loss: 0.9672, Accuracy: 74.00%\n",
      "Epoch [2/15], Step [200/600], Loss: 0.8345, Accuracy: 78.00%\n",
      "Epoch [2/15], Step [300/600], Loss: 0.8401, Accuracy: 79.00%\n",
      "Epoch [2/15], Step [400/600], Loss: 1.1615, Accuracy: 84.00%\n",
      "Epoch [2/15], Step [500/600], Loss: 0.9892, Accuracy: 76.00%\n",
      "Epoch [2/15], Step [600/600], Loss: 0.6248, Accuracy: 84.00%\n",
      "Epoch [3/15], Step [100/600], Loss: 0.7774, Accuracy: 79.00%\n",
      "Epoch [3/15], Step [200/600], Loss: 0.5385, Accuracy: 80.00%\n",
      "Epoch [3/15], Step [300/600], Loss: 1.0808, Accuracy: 81.00%\n",
      "Epoch [3/15], Step [400/600], Loss: 1.4527, Accuracy: 74.00%\n",
      "Epoch [3/15], Step [500/600], Loss: 1.0136, Accuracy: 77.00%\n",
      "Epoch [3/15], Step [600/600], Loss: 0.5730, Accuracy: 83.00%\n",
      "Epoch [4/15], Step [100/600], Loss: 0.4573, Accuracy: 87.00%\n",
      "Epoch [4/15], Step [200/600], Loss: 0.5255, Accuracy: 84.00%\n",
      "Epoch [4/15], Step [300/600], Loss: 0.7053, Accuracy: 82.00%\n",
      "Epoch [4/15], Step [400/600], Loss: 0.6504, Accuracy: 88.00%\n",
      "Epoch [4/15], Step [500/600], Loss: 0.6409, Accuracy: 86.00%\n",
      "Epoch [4/15], Step [600/600], Loss: 0.6621, Accuracy: 84.00%\n",
      "Epoch [5/15], Step [100/600], Loss: 0.5998, Accuracy: 87.00%\n",
      "Epoch [5/15], Step [200/600], Loss: 0.8051, Accuracy: 81.00%\n",
      "Epoch [5/15], Step [300/600], Loss: 0.6095, Accuracy: 87.00%\n",
      "Epoch [5/15], Step [400/600], Loss: 0.3405, Accuracy: 92.00%\n",
      "Epoch [5/15], Step [500/600], Loss: 0.7923, Accuracy: 82.00%\n",
      "Epoch [5/15], Step [600/600], Loss: 0.7055, Accuracy: 84.00%\n",
      "Epoch [6/15], Step [100/600], Loss: 0.5619, Accuracy: 85.00%\n",
      "Epoch [6/15], Step [200/600], Loss: 0.6532, Accuracy: 81.00%\n",
      "Epoch [6/15], Step [300/600], Loss: 0.8926, Accuracy: 85.00%\n",
      "Epoch [6/15], Step [400/600], Loss: 0.4817, Accuracy: 87.00%\n",
      "Epoch [6/15], Step [500/600], Loss: 0.4968, Accuracy: 90.00%\n",
      "Epoch [6/15], Step [600/600], Loss: 0.2436, Accuracy: 91.00%\n",
      "Epoch [7/15], Step [100/600], Loss: 0.6895, Accuracy: 84.00%\n",
      "Epoch [7/15], Step [200/600], Loss: 0.4285, Accuracy: 86.00%\n",
      "Epoch [7/15], Step [300/600], Loss: 0.5157, Accuracy: 84.00%\n",
      "Epoch [7/15], Step [400/600], Loss: 0.4670, Accuracy: 87.00%\n",
      "Epoch [7/15], Step [500/600], Loss: 0.5113, Accuracy: 83.00%\n",
      "Epoch [7/15], Step [600/600], Loss: 0.5745, Accuracy: 87.00%\n",
      "Epoch [8/15], Step [100/600], Loss: 0.9683, Accuracy: 86.00%\n",
      "Epoch [8/15], Step [200/600], Loss: 0.6237, Accuracy: 86.00%\n",
      "Epoch [8/15], Step [300/600], Loss: 0.5487, Accuracy: 85.00%\n",
      "Epoch [8/15], Step [400/600], Loss: 0.6880, Accuracy: 83.00%\n",
      "Epoch [8/15], Step [500/600], Loss: 0.3166, Accuracy: 92.00%\n",
      "Epoch [8/15], Step [600/600], Loss: 0.4619, Accuracy: 85.00%\n",
      "Epoch [9/15], Step [100/600], Loss: 0.8060, Accuracy: 85.00%\n",
      "Epoch [9/15], Step [200/600], Loss: 0.6738, Accuracy: 86.00%\n",
      "Epoch [9/15], Step [300/600], Loss: 0.2311, Accuracy: 92.00%\n",
      "Epoch [9/15], Step [400/600], Loss: 0.8286, Accuracy: 84.00%\n",
      "Epoch [9/15], Step [500/600], Loss: 1.0976, Accuracy: 86.00%\n",
      "Epoch [9/15], Step [600/600], Loss: 0.6993, Accuracy: 82.00%\n",
      "Epoch [10/15], Step [100/600], Loss: 0.5784, Accuracy: 84.00%\n",
      "Epoch [10/15], Step [200/600], Loss: 0.4410, Accuracy: 90.00%\n",
      "Epoch [10/15], Step [300/600], Loss: 0.8283, Accuracy: 85.00%\n",
      "Epoch [10/15], Step [400/600], Loss: 0.7485, Accuracy: 82.00%\n",
      "Epoch [10/15], Step [500/600], Loss: 0.3823, Accuracy: 90.00%\n",
      "Epoch [10/15], Step [600/600], Loss: 0.3677, Accuracy: 89.00%\n",
      "Epoch [11/15], Step [100/600], Loss: 0.2673, Accuracy: 92.00%\n",
      "Epoch [11/15], Step [200/600], Loss: 0.5009, Accuracy: 90.00%\n",
      "Epoch [11/15], Step [300/600], Loss: 0.4425, Accuracy: 90.00%\n",
      "Epoch [11/15], Step [400/600], Loss: 0.9706, Accuracy: 82.00%\n",
      "Epoch [11/15], Step [500/600], Loss: 0.3557, Accuracy: 88.00%\n",
      "Epoch [11/15], Step [600/600], Loss: 0.5028, Accuracy: 85.00%\n",
      "Epoch [12/15], Step [100/600], Loss: 0.2809, Accuracy: 94.00%\n",
      "Epoch [12/15], Step [200/600], Loss: 0.3497, Accuracy: 92.00%\n",
      "Epoch [12/15], Step [300/600], Loss: 0.8452, Accuracy: 83.00%\n",
      "Epoch [12/15], Step [400/600], Loss: 0.4679, Accuracy: 86.00%\n",
      "Epoch [12/15], Step [500/600], Loss: 0.5129, Accuracy: 90.00%\n",
      "Epoch [12/15], Step [600/600], Loss: 0.4975, Accuracy: 89.00%\n",
      "Epoch [13/15], Step [100/600], Loss: 0.5996, Accuracy: 91.00%\n",
      "Epoch [13/15], Step [200/600], Loss: 0.5277, Accuracy: 87.00%\n",
      "Epoch [13/15], Step [300/600], Loss: 0.6790, Accuracy: 86.00%\n",
      "Epoch [13/15], Step [400/600], Loss: 0.3444, Accuracy: 90.00%\n",
      "Epoch [13/15], Step [500/600], Loss: 0.6399, Accuracy: 85.00%\n",
      "Epoch [13/15], Step [600/600], Loss: 0.5831, Accuracy: 85.00%\n",
      "Epoch [14/15], Step [100/600], Loss: 0.9834, Accuracy: 82.00%\n",
      "Epoch [14/15], Step [200/600], Loss: 0.1907, Accuracy: 93.00%\n",
      "Epoch [14/15], Step [300/600], Loss: 0.6639, Accuracy: 92.00%\n",
      "Epoch [14/15], Step [400/600], Loss: 0.6663, Accuracy: 86.00%\n",
      "Epoch [14/15], Step [500/600], Loss: 0.5859, Accuracy: 86.00%\n",
      "Epoch [14/15], Step [600/600], Loss: 0.4308, Accuracy: 86.00%\n",
      "Epoch [15/15], Step [100/600], Loss: 1.1125, Accuracy: 87.00%\n",
      "Epoch [15/15], Step [200/600], Loss: 0.2523, Accuracy: 90.00%\n",
      "Epoch [15/15], Step [300/600], Loss: 0.4955, Accuracy: 87.00%\n",
      "Epoch [15/15], Step [400/600], Loss: 0.4271, Accuracy: 87.00%\n",
      "Epoch [15/15], Step [500/600], Loss: 0.4371, Accuracy: 89.00%\n",
      "Epoch [15/15], Step [600/600], Loss: 0.4877, Accuracy: 89.00%\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(training_epochs):\n",
    "    for i, (imgs, labels) in enumerate(train_loader):\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        imgs = imgs.view(-1, 28*28)\n",
    "        \n",
    "        outputs = linear(imgs) #imgs를 linear layer의 입력으로 넣어 classifier가 분류한 결과를 얻는다.\n",
    "        loss = criterion(outputs, labels) #classifier가 분류한 결과와 실제 label로 cross_entropy를 진행한다.\n",
    "        \n",
    "        optimizer.zero_grad() #gradient 초기화\n",
    "        loss.backward() #gradient를 계산해서 업데이트\n",
    "        optimizer.step() #개선\n",
    "        \n",
    "        _, argmax = torch.max(outputs, 1) #max()를 이용해 최종 출력이 가장 높은 class 선택\n",
    "        accuracy = (labels == argmax).float().mean()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%'.format(epoch+1, training_epochs, i+1, len(train_loader), loss.item(), accuracy.item() * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde02fc4",
   "metadata": {},
   "source": [
    "Q5. 학습이 완료되면, 모델이 잘 동작하는지 테스트가 필요합니다. 데이터로드 파트에서 준비했던 테스트 데이터를 이용해 테스트를 진행해봅시다. 아래 테스트 코드를 완성해보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a2c20fe4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy for 10000 images: 89.01%\n"
     ]
    }
   ],
   "source": [
    "linear.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for i, (imgs, labels) in enumerate(test_loader):\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        imgs = imgs.view(-1, 28 * 28)\n",
    "    \n",
    "        outputs = linear(imgs)\n",
    "        \n",
    "        _, argmax = torch.max(outputs, 1) #max()를 이용해 최종 출력이 가장 높은 class 선택\n",
    "        \n",
    "        for label, argmax in zip(labels, argmax):\n",
    "            if label == argmax: #label이 argmax와 일치하면 correct를 +1 해주기\n",
    "                correct += 1\n",
    "            total += 1 #반복문 돌 때마다 total +1 해주기\n",
    "        \n",
    "    print('Test accuracy for {} images: {:.2f}%'.format(total, correct / total * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
